{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4fe11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d8ef95",
   "metadata": {},
   "source": [
    "Zanim zbudujemy CNN w Keras, musimy zrozumieć konwolucję i pooling. Załaduj obraz „data/zebra.jpg”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47139a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zebra = tf.keras.preprocessing.image.load_img(\"data/zebra.jpg\", color_mode = \"grayscale\", target_size = (200, 300))\n",
    "zebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zebra_array = tf.keras.preprocessing.image.img_to_array(zebra) / 255\n",
    "print(zebra_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314aba49",
   "metadata": {},
   "source": [
    "Teraz możemy zaimplementować prostą konwolucję:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0428a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_filter_x = np.transpose(np.array([1, 2, 1, 0, 0, 0, -1, -2, -1]).reshape((3, 3)))\n",
    "sobel_filter_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bfb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_shape = 3\n",
    "padding = 0\n",
    "stride = 1\n",
    "input_height = zebra_array.shape[0]\n",
    "input_width = zebra_array.shape[1]\n",
    "activation_map_height = int((input_height + 2 * padding - kernel_shape) / stride + 1)\n",
    "activation_map_width = int((input_width + 2 * padding - kernel_shape) / stride + 1)\n",
    "activation_map = np.zeros((activation_map_height, activation_map_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8f8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in range(0, activation_map_width):\n",
    "    for h in range(0, activation_map_height):\n",
    "        activation_map[h, w] = np.sum(sobel_filter_x * zebra_array[h:(h + kernel_shape), w:(w + kernel_shape), 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(activation_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971975b",
   "metadata": {},
   "source": [
    "oraz pooling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678001bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_shape = 2\n",
    "pool_stride = 2\n",
    "activation_map2_height = int(activation_map_height / pool_shape)\n",
    "activation_map2_width = int(activation_map_width / pool_shape)\n",
    "activation_map2 = np.zeros((activation_map2_height, activation_map2_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in range(0, activation_map2_width):\n",
    "    for h in range(0, activation_map2_height):\n",
    "        activation_map2[h, w] = np.max(activation_map[(2 * h):((2 * h) + pool_shape), (2 * w):((2 * w) + pool_shape)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ae83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(activation_map2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2163900",
   "metadata": {},
   "source": [
    "Zaczniemy od zbudowania prostego CNN dla zbioru danych dotyczących mody. Na pierwszym spotkaniu stworzyliśmy MLP do tego zadania. Załadujmy zbiór danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_train_X = pd.read_csv(\"data/fashion_mnist_train_X\", sep=\" \").to_numpy()\n",
    "fashion_mnist_test_X = pd.read_csv(\"data/fashion_mnist_test_X\", sep=\" \").to_numpy()\n",
    "fashion_mnist_train_Y = pd.read_csv(\"data/fashion_mnist_train_Y\", sep=\" \").to_numpy()\n",
    "fashion_mnist_test_Y = pd.read_csv(\"data/fashion_mnist_test_Y\", sep=\" \").to_numpy()\n",
    "\n",
    "fashion_mnist_train_X = fashion_mnist_train_X / 255\n",
    "fashion_mnist_test_X = fashion_mnist_test_X / 255\n",
    "\n",
    "print(fashion_mnist_train_X.shape)\n",
    "print(fashion_mnist_train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2dc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(fashion_mnist_train_X[0,:].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e957fbab",
   "metadata": {},
   "source": [
    "Aby przesłać dane do modelu CNN w keras, musimy przekształcić je w odpowiednie tensory. Podobnie jak w przypadku MLP musimy przekształcić wektor etykiet do macierzy z kodowaniem one-hot-encoding. W przypadku naszych obrazów musimy przedstawić je jako tensor 4-wymiarowy (próbki, wysokość, szerokość, kanały). Musimy również pamiętać o znormalizowaniu wartości pikseli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_train_Y = tf.keras.utils.to_categorical(fashion_mnist_train_Y, 10)\n",
    "fashion_mnist_test_Y = tf.keras.utils.to_categorical(fashion_mnist_test_Y, 10)\n",
    "\n",
    "fashion_mnist_train_X = fashion_mnist_train_X.reshape(-1, 28, 28, 1)\n",
    "fashion_mnist_test_X = fashion_mnist_test_X.reshape(-1, 28, 28, 1)\n",
    "print(fashion_mnist_train_X.shape)\n",
    "print(fashion_mnist_train_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d86d4a",
   "metadata": {},
   "source": [
    "Dane są w poprawnej formie tensorowej, możemy przystąpić do budowy modelu. Jak zawsze będzie to model sekwencyjny. Jako pierwszą warstwę użyjemy warstwy konwolucyjnej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f740c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_model1 = tf.keras.Sequential()\n",
    "\n",
    "fmnist_model1.add(\n",
    "    tf.keras.layers.Conv2D(filters = 32, # Liczba filtrów\n",
    "                           kernel_size = (3, 3), # Wielkość filtrów\n",
    "                           activation = 'relu',\n",
    "                            input_shape = (28, 28, 1))\n",
    ")\n",
    "fmnist_model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8aa16d",
   "metadata": {},
   "source": [
    "Dlaczego mamy do wytrenowania 320 parametrów?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3073aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "32 * (3 * 3 * 1 + 1) # 32 filters of size 3x3(x1) + bias for each of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d871a3a",
   "metadata": {},
   "source": [
    "Dlaczego output ma kształt (None, 26, 26, 32) ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240514a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "((28 - 3 + 2 * 0) / 1) + 1 # 28 - input image size, 3 - kernsl size, 0 - padding, 1 - stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d666bb",
   "metadata": {},
   "source": [
    "Po warstwie konwolucyjnej możemy dodać kolejną. Użyjmy warstwy max pooling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_model1.add(\n",
    "    tf.keras.layers.MaxPool2D(pool_size = (2, 2))\n",
    ")\n",
    "fmnist_model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcde1d4",
   "metadata": {},
   "source": [
    "Dlaczego output ma kształt (None, 12, 12, 32) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "26 / 2 # 26 - input of the activation map shape, 2 - pool size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35c2f68",
   "metadata": {},
   "source": [
    "Powiedzmy, że chcemy dokończyć naszą architekturę i dodać warstwę wyjściową. zrobimy to w taki sam sposób jak w MLP, ale zanim to zrobimy, musimy spłaszczyć naszą ostatnią mapę aktywacji do wektora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ac7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_model1.add(\n",
    "    tf.keras.layers.Flatten()\n",
    ")\n",
    "\n",
    "fmnist_model1.add(\n",
    "    tf.keras.layers.Dense(units = 10, activation = \"softmax\")\n",
    ")\n",
    "fmnist_model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0feeaa8",
   "metadata": {},
   "source": [
    "Dlaczego output ma kształt (None, 5408) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab353f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "13 * 13 * 32 # Check dimmentions of previous layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92271a7c",
   "metadata": {},
   "source": [
    "Dlaczego mamy 54090 parametrów do trenowania w warstwie wyjściowej?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a0b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "5408 * 10 + 10 # 5408 - from layer_flatten * 10 neurons + biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d6941",
   "metadata": {},
   "source": [
    "Architertura CNN jest ukończona, możemy teraz skompilować model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_model1.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = (\"accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b327d0",
   "metadata": {},
   "source": [
    "i go wytrenować:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f456657",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fmnist_model1.fit(\n",
    "    x = fashion_mnist_train_X,\n",
    "    y = fashion_mnist_train_Y,\n",
    "    validation_split = 0.2, # 20% zbioru uczącego przeznaczonego na walidację\n",
    "    epochs = 30, # Liczba \"pętli/przejść\" bo całym zbiorze treningowym\n",
    "    batch_size = 128, # Wielkość próbki (batcha) dla jednej iteracji algorytmu SGD\n",
    "    verbose = 1,\n",
    "    callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath = \"models/fmnist_model1_best.hdf5\",\n",
    "                                                  monitor = \"val_loss\", save_best_only = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e198c7e",
   "metadata": {},
   "source": [
    "oraz zewaluować na zbiorze testowym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feefa76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_model1.evaluate(fashion_mnist_test_X, fashion_mnist_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf065ab",
   "metadata": {},
   "source": [
    "Czas na stworzenie bardziej zaawansowanej wersji tego modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46caaec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zainicjalizuj model\n",
    "fmnist_model2 = tf.keras.Sequential()\n",
    "\n",
    "# Dodaj warstwę konwolucyjną: 128 filtróœ, 3x3, liniowa aktywacja, padding \"same\"\n",
    "___\n",
    "# Dodaj BatchNormalization\n",
    "___\n",
    "# Dodaj aktywację ReLU\n",
    "___\n",
    "# Dodaj MaaxPooling 2x2, strides 2\n",
    "___\n",
    "# Dodaj dropout 25%\n",
    "___\n",
    "# Dodaj warstwę spłaszczającą\n",
    "___\n",
    "# Dodaj output\n",
    "___\n",
    "\n",
    "fmnist_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_model2.compile(\n",
    "    optimizer = tf.keras.optimizers.Adadelta(lr = 0.01, decay = 1e-6),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = (\"accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"tensorboard\"):\n",
    "    os.mkdir(\"tensorboard\")\n",
    "\n",
    "history = fmnist_model1.fit(\n",
    "    x = fashion_mnist_train_X,\n",
    "    y = fashion_mnist_train_Y,\n",
    "    validation_split = 0.2, # 20% zbioru uczącego przeznaczonego na walidację\n",
    "    epochs = 30, # Liczba \"pętli/przejść\" bo całym zbiorze treningowym\n",
    "    batch_size = 128, # Wielkość próbki (batcha) dla jednej iteracji algorytmu SGD\n",
    "    verbose = 1,\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', patience = 5),\n",
    "                 tf.keras.callbacks.ModelCheckpoint(filepath = \"models/fmnist_model2_best.hdf5\",\n",
    "                                                  monitor = \"val_accuracy\", save_best_only = True),\n",
    "                tf.keras.callbacks.TensorBoard(log_dir = \"tensorboard\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf52be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af49629",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee309fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
