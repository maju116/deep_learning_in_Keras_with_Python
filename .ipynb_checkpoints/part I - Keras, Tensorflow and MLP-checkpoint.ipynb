{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c87b514",
   "metadata": {},
   "source": [
    "Zacznijmy od wczytania niezbędnych pakietów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e343c4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b602c",
   "metadata": {},
   "source": [
    "# MLP dla zadania regresji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83d37f",
   "metadata": {},
   "source": [
    "W Keras możemy tworzyć modele na dwa różne sposoby:\n",
    "- zbudować model sekwencyjny - nakładamy nowe warstwy na poprzednie. Nie możemy używać wielu inputów i outputów w modelu.\n",
    "- używając API funkcyjnego - pozwala na uzycie wieli inputów i uotputów.\n",
    "\n",
    "Zaczniemy od modelu sekwencyjnego. Musimy zacząć od inicjalizacji modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f83119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(404, 1)\n"
     ]
    }
   ],
   "source": [
    "boston_train_X = pd.read_csv(\"data/boston_train_X\", sep=\" \").to_numpy()\n",
    "boston_test_X = pd.read_csv(\"data/boston_test_X\", sep=\" \").to_numpy()\n",
    "boston_train_Y = pd.read_csv(\"data/boston_train_Y\", sep=\" \").to_numpy()\n",
    "boston_test_Y = pd.read_csv(\"data/boston_test_Y\", sep=\" \").to_numpy()\n",
    "\n",
    "print(boston_train_X.shape)\n",
    "print(boston_train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e239ef82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27190919, -0.48301657, -0.43522197, ...,  1.14707815,\n",
       "         0.44752224,  0.82419825],\n",
       "       [-0.40292691,  2.9880792 , -1.33225971, ..., -1.7160613 ,\n",
       "         0.43137112, -1.32755632],\n",
       "       [ 0.12478548, -0.48301657,  1.02705233, ...,  0.78350488,\n",
       "         0.22034405, -1.30687963],\n",
       "       ...,\n",
       "       [-0.401532  ,  0.98956951, -0.74059652, ..., -0.71623483,\n",
       "         0.07934057, -0.6769297 ],\n",
       "       [-0.17270603, -0.48301657,  1.24433806, ..., -1.7160613 ,\n",
       "        -0.98642053,  0.42031351],\n",
       "       [-0.40372555,  2.04141672, -1.20012649, ..., -1.30704138,\n",
       "         0.23288242, -1.15249365]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a9803f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.2],\n",
       "       [42.3],\n",
       "       [50. ],\n",
       "       [21.1],\n",
       "       [17.7],\n",
       "       [18.5],\n",
       "       [11.3],\n",
       "       [15.6],\n",
       "       [15.6],\n",
       "       [14.4],\n",
       "       [12.1],\n",
       "       [17.9],\n",
       "       [23.1],\n",
       "       [19.9],\n",
       "       [15.7],\n",
       "       [ 8.8],\n",
       "       [50. ],\n",
       "       [22.5],\n",
       "       [24.1],\n",
       "       [27.5],\n",
       "       [10.9],\n",
       "       [30.8],\n",
       "       [32.9],\n",
       "       [24. ],\n",
       "       [18.5],\n",
       "       [13.3],\n",
       "       [22.9],\n",
       "       [34.7],\n",
       "       [16.6],\n",
       "       [17.5],\n",
       "       [22.3],\n",
       "       [16.1],\n",
       "       [14.9],\n",
       "       [23.1],\n",
       "       [34.9],\n",
       "       [25. ],\n",
       "       [13.9],\n",
       "       [13.1],\n",
       "       [20.4],\n",
       "       [20. ],\n",
       "       [15.2],\n",
       "       [24.7],\n",
       "       [22.2],\n",
       "       [16.7],\n",
       "       [12.7],\n",
       "       [15.6],\n",
       "       [18.4],\n",
       "       [21. ],\n",
       "       [30.1],\n",
       "       [15.1],\n",
       "       [18.7],\n",
       "       [ 9.6],\n",
       "       [31.5],\n",
       "       [24.8],\n",
       "       [19.1],\n",
       "       [22. ],\n",
       "       [14.5],\n",
       "       [11. ],\n",
       "       [32. ],\n",
       "       [29.4],\n",
       "       [20.3],\n",
       "       [24.4],\n",
       "       [14.6],\n",
       "       [19.5],\n",
       "       [14.1],\n",
       "       [14.3],\n",
       "       [15.6],\n",
       "       [10.5],\n",
       "       [ 6.3],\n",
       "       [19.3],\n",
       "       [19.3],\n",
       "       [13.4],\n",
       "       [36.4],\n",
       "       [17.8],\n",
       "       [13.5],\n",
       "       [16.5],\n",
       "       [ 8.3],\n",
       "       [14.3],\n",
       "       [16. ],\n",
       "       [13.4],\n",
       "       [28.6],\n",
       "       [43.5],\n",
       "       [20.2],\n",
       "       [22. ],\n",
       "       [23. ],\n",
       "       [20.7],\n",
       "       [12.5],\n",
       "       [48.5],\n",
       "       [14.6],\n",
       "       [13.4],\n",
       "       [23.7],\n",
       "       [50. ],\n",
       "       [21.7],\n",
       "       [39.8],\n",
       "       [38.7],\n",
       "       [22.2],\n",
       "       [34.9],\n",
       "       [22.5],\n",
       "       [31.1],\n",
       "       [28.7],\n",
       "       [46. ],\n",
       "       [41.7],\n",
       "       [21. ],\n",
       "       [26.6],\n",
       "       [15. ],\n",
       "       [24.4],\n",
       "       [13.3],\n",
       "       [21.2],\n",
       "       [11.7],\n",
       "       [21.7],\n",
       "       [19.4],\n",
       "       [50. ],\n",
       "       [22.8],\n",
       "       [19.7],\n",
       "       [24.7],\n",
       "       [36.2],\n",
       "       [14.2],\n",
       "       [18.9],\n",
       "       [18.3],\n",
       "       [20.6],\n",
       "       [24.6],\n",
       "       [18.2],\n",
       "       [ 8.7],\n",
       "       [44. ],\n",
       "       [10.4],\n",
       "       [13.2],\n",
       "       [21.2],\n",
       "       [37. ],\n",
       "       [30.7],\n",
       "       [22.9],\n",
       "       [20. ],\n",
       "       [19.3],\n",
       "       [31.7],\n",
       "       [32. ],\n",
       "       [23.1],\n",
       "       [18.8],\n",
       "       [10.9],\n",
       "       [50. ],\n",
       "       [19.6],\n",
       "       [ 5. ],\n",
       "       [14.4],\n",
       "       [19.8],\n",
       "       [13.8],\n",
       "       [19.6],\n",
       "       [23.9],\n",
       "       [24.5],\n",
       "       [25. ],\n",
       "       [19.9],\n",
       "       [17.2],\n",
       "       [24.6],\n",
       "       [13.5],\n",
       "       [26.6],\n",
       "       [21.4],\n",
       "       [11.9],\n",
       "       [22.6],\n",
       "       [19.6],\n",
       "       [ 8.5],\n",
       "       [23.7],\n",
       "       [23.1],\n",
       "       [22.4],\n",
       "       [20.5],\n",
       "       [23.6],\n",
       "       [18.4],\n",
       "       [35.2],\n",
       "       [23.1],\n",
       "       [27.9],\n",
       "       [20.6],\n",
       "       [23.7],\n",
       "       [28. ],\n",
       "       [13.6],\n",
       "       [27.1],\n",
       "       [23.6],\n",
       "       [20.6],\n",
       "       [18.2],\n",
       "       [21.7],\n",
       "       [17.1],\n",
       "       [ 8.4],\n",
       "       [25.3],\n",
       "       [13.8],\n",
       "       [22.2],\n",
       "       [18.4],\n",
       "       [20.7],\n",
       "       [31.6],\n",
       "       [30.5],\n",
       "       [20.3],\n",
       "       [ 8.8],\n",
       "       [19.2],\n",
       "       [19.4],\n",
       "       [23.1],\n",
       "       [23. ],\n",
       "       [14.8],\n",
       "       [48.8],\n",
       "       [22.6],\n",
       "       [33.4],\n",
       "       [21.1],\n",
       "       [13.6],\n",
       "       [32.2],\n",
       "       [13.1],\n",
       "       [23.4],\n",
       "       [18.9],\n",
       "       [23.9],\n",
       "       [11.8],\n",
       "       [23.3],\n",
       "       [22.8],\n",
       "       [19.6],\n",
       "       [16.7],\n",
       "       [13.4],\n",
       "       [22.2],\n",
       "       [20.4],\n",
       "       [21.8],\n",
       "       [26.4],\n",
       "       [14.9],\n",
       "       [24.1],\n",
       "       [23.8],\n",
       "       [12.3],\n",
       "       [29.1],\n",
       "       [21. ],\n",
       "       [19.5],\n",
       "       [23.3],\n",
       "       [23.8],\n",
       "       [17.8],\n",
       "       [11.5],\n",
       "       [21.7],\n",
       "       [19.9],\n",
       "       [25. ],\n",
       "       [33.4],\n",
       "       [28.5],\n",
       "       [21.4],\n",
       "       [24.3],\n",
       "       [27.5],\n",
       "       [33.1],\n",
       "       [16.2],\n",
       "       [23.3],\n",
       "       [48.3],\n",
       "       [22.9],\n",
       "       [22.8],\n",
       "       [13.1],\n",
       "       [12.7],\n",
       "       [22.6],\n",
       "       [15. ],\n",
       "       [15.3],\n",
       "       [10.5],\n",
       "       [24. ],\n",
       "       [18.5],\n",
       "       [21.7],\n",
       "       [19.5],\n",
       "       [33.2],\n",
       "       [23.2],\n",
       "       [ 5. ],\n",
       "       [19.1],\n",
       "       [12.7],\n",
       "       [22.3],\n",
       "       [10.2],\n",
       "       [13.9],\n",
       "       [16.3],\n",
       "       [17. ],\n",
       "       [20.1],\n",
       "       [29.9],\n",
       "       [17.2],\n",
       "       [37.3],\n",
       "       [45.4],\n",
       "       [17.8],\n",
       "       [23.2],\n",
       "       [29. ],\n",
       "       [22. ],\n",
       "       [18. ],\n",
       "       [17.4],\n",
       "       [34.6],\n",
       "       [20.1],\n",
       "       [25. ],\n",
       "       [15.6],\n",
       "       [24.8],\n",
       "       [28.2],\n",
       "       [21.2],\n",
       "       [21.4],\n",
       "       [23.8],\n",
       "       [31. ],\n",
       "       [26.2],\n",
       "       [17.4],\n",
       "       [37.9],\n",
       "       [17.5],\n",
       "       [20. ],\n",
       "       [ 8.3],\n",
       "       [23.9],\n",
       "       [ 8.4],\n",
       "       [13.8],\n",
       "       [ 7.2],\n",
       "       [11.7],\n",
       "       [17.1],\n",
       "       [21.6],\n",
       "       [50. ],\n",
       "       [16.1],\n",
       "       [20.4],\n",
       "       [20.6],\n",
       "       [21.4],\n",
       "       [20.6],\n",
       "       [36.5],\n",
       "       [ 8.5],\n",
       "       [24.8],\n",
       "       [10.8],\n",
       "       [21.9],\n",
       "       [17.3],\n",
       "       [18.9],\n",
       "       [36.2],\n",
       "       [14.9],\n",
       "       [18.2],\n",
       "       [33.3],\n",
       "       [21.8],\n",
       "       [19.7],\n",
       "       [31.6],\n",
       "       [24.8],\n",
       "       [19.4],\n",
       "       [22.8],\n",
       "       [ 7.5],\n",
       "       [44.8],\n",
       "       [16.8],\n",
       "       [18.7],\n",
       "       [50. ],\n",
       "       [50. ],\n",
       "       [19.5],\n",
       "       [20.1],\n",
       "       [50. ],\n",
       "       [17.2],\n",
       "       [20.8],\n",
       "       [19.3],\n",
       "       [41.3],\n",
       "       [20.4],\n",
       "       [20.5],\n",
       "       [13.8],\n",
       "       [16.5],\n",
       "       [23.9],\n",
       "       [20.6],\n",
       "       [31.5],\n",
       "       [23.3],\n",
       "       [16.8],\n",
       "       [14. ],\n",
       "       [33.8],\n",
       "       [36.1],\n",
       "       [12.8],\n",
       "       [18.3],\n",
       "       [18.7],\n",
       "       [19.1],\n",
       "       [29. ],\n",
       "       [30.1],\n",
       "       [50. ],\n",
       "       [50. ],\n",
       "       [22. ],\n",
       "       [11.9],\n",
       "       [37.6],\n",
       "       [50. ],\n",
       "       [22.7],\n",
       "       [20.8],\n",
       "       [23.5],\n",
       "       [27.9],\n",
       "       [50. ],\n",
       "       [19.3],\n",
       "       [23.9],\n",
       "       [22.6],\n",
       "       [15.2],\n",
       "       [21.7],\n",
       "       [19.2],\n",
       "       [43.8],\n",
       "       [20.3],\n",
       "       [33.2],\n",
       "       [19.9],\n",
       "       [22.5],\n",
       "       [32.7],\n",
       "       [22. ],\n",
       "       [17.1],\n",
       "       [19. ],\n",
       "       [15. ],\n",
       "       [16.1],\n",
       "       [25.1],\n",
       "       [23.7],\n",
       "       [28.7],\n",
       "       [37.2],\n",
       "       [22.6],\n",
       "       [16.4],\n",
       "       [25. ],\n",
       "       [29.8],\n",
       "       [22.1],\n",
       "       [17.4],\n",
       "       [18.1],\n",
       "       [30.3],\n",
       "       [17.5],\n",
       "       [24.7],\n",
       "       [12.6],\n",
       "       [26.5],\n",
       "       [28.7],\n",
       "       [13.3],\n",
       "       [10.4],\n",
       "       [24.4],\n",
       "       [23. ],\n",
       "       [20. ],\n",
       "       [17.8],\n",
       "       [ 7. ],\n",
       "       [11.8],\n",
       "       [24.4],\n",
       "       [13.8],\n",
       "       [19.4],\n",
       "       [25.2],\n",
       "       [19.4],\n",
       "       [19.4],\n",
       "       [29.1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbacf764",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f9dabc",
   "metadata": {},
   "source": [
    "W następnym kroku możemy dodać kilka warstw (pamiętaj, że nie musimy ponownie przypisywać modelu za pomocą `=`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33421632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                224       \n",
      "=================================================================\n",
      "Total params: 224\n",
      "Trainable params: 224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "boston_model.add(\n",
    "    tf.keras.layers.Dense(units = 16, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"tanh\", # Funkcja aktywacji\n",
    "                             input_shape = (13,)) # Liczba predyktorów - tylko w pierwszej warstwie\n",
    ")\n",
    "boston_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b8ac6",
   "metadata": {},
   "source": [
    "Dlaczego mamy 224 parametry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f3256a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13 * 16 + 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8e67c",
   "metadata": {},
   "source": [
    "Po dodaniu warstwy ukrytej możemy dodać warstwę wyjściową:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d84e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                224       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "boston_model.add(\n",
    "    tf.keras.layers.Dense(units = 1, # Liczba neuronów w warstwie wyjścia - chcemy dostać 1 liczbę\n",
    "                             activation = \"linear\") # Funkcja liniowa dla regresji\n",
    ")\n",
    "boston_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b27f65",
   "metadata": {},
   "source": [
    "Możemy teraz skonfigurować model do treningu. Użyjemy SGD jako optymalizatora, MSE jako funkcji straty i dodamy MAE jako dodatkową metrykę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b0f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"mse\",\n",
    "    metrics = (\"mae\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85acce42",
   "metadata": {},
   "source": [
    "Jesteśmy gotowi do trenowania naszej pierwszej sieci neuronowej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dacb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = boston_model.fit(\n",
    "    x = boston_train_X,\n",
    "    y = boston_train_Y,\n",
    "    validation_split = 0.2, # 20% zbioru uczącego przeznaczonego na walidację\n",
    "    epochs = 5, # Liczba \"pętli/przejść\" bo całym zbiorze treningowym\n",
    "    batch_size = 30, # Wielkość próbki (batcha) dla jednej iteracji algorytmu SGD\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47177f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('model MAE')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f57ba",
   "metadata": {},
   "source": [
    "Możemy teraz ocenić wytrenowany model w testowym zestawie danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model.evaluate(boston_test_X, boston_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e862b2",
   "metadata": {},
   "source": [
    "I policzyć predykcje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_predictions = boston_model.predict(boston_test_X)\n",
    "boston_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc33904",
   "metadata": {},
   "source": [
    "Na koniec możemy zapisać nasz model na dysku twardym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101913a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "boston_model.save(\"models/boston_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f1ea8",
   "metadata": {},
   "source": [
    "# MLP dla zadania klasyfikacji binarnej"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185bb493",
   "metadata": {},
   "source": [
    "Budując MLP (lub inną sieć neuronową) dla zadania klasyfikacji musimy zmienić tylko kilka drobnych detali w naszym kodzie. Zacznijmy od wczytania zbioru danych z informacjami o fraudach na kartach kredytowych i inicjalizacji modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cc65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_train_X = pd.read_csv(\"data/creditcard_train_X\", sep=\" \").to_numpy()\n",
    "creditcard_test_X = pd.read_csv(\"data/creditcard_test_X\", sep=\" \").to_numpy()\n",
    "creditcard_train_Y = pd.read_csv(\"data/creditcard_train_Y\", sep=\" \").to_numpy()\n",
    "creditcard_test_Y = pd.read_csv(\"data/creditcard_test_Y\", sep=\" \").to_numpy()\n",
    "\n",
    "print(creditcard_train_X.shape)\n",
    "print(creditcard_train_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240de081",
   "metadata": {},
   "source": [
    "Zanim zbudujemy model, przekształcimy wektor odpowiedzi (klas) do formatu one-hot-encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be130f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_train_Y = tf.keras.utils.to_categorical(creditcard_train_Y, 2)\n",
    "creditcard_test_Y = tf.keras.utils.to_categorical(creditcard_test_Y, 2)\n",
    "print(creditcard_train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddedee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3604d48c",
   "metadata": {},
   "source": [
    "Następnie dodajmy warstwy ukryte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85238d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model.add(\n",
    "    tf.keras.layers.Dense(units = 20, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"relu\", # Funkcja aktywacji\n",
    "                             input_shape = (29,)) # Liczba predyktorów - tylko w pierwszej warstwie\n",
    ")\n",
    "creditcard_model.add(\n",
    "    tf.keras.layers.Dense(units = 10, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"relu\") # Funkcja aktywacji\n",
    ")\n",
    "creditcard_model.add(\n",
    "    tf.keras.layers.Dense(units = 5, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"relu\") # Funkcja aktywacji\n",
    ")\n",
    "creditcard_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c06c97b",
   "metadata": {},
   "source": [
    "Oraz warstwę wyjściową:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f665bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model.add(\n",
    "    tf.keras.layers.Dense(units = 2, # Liczba neuronów w warstwie wyjścia - dwie klasy\n",
    "                             activation = \"softmax\") # Funkcja aktywacji - softmax dla klasykikacji\n",
    ")\n",
    "creditcard_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58794f1",
   "metadata": {},
   "source": [
    "Możemy teraz skonfigurować model do treningu. Użyjemy SGD jako optymalizatora, Entropii Krzyżowej jako funkcji straty i dodamy Accuracy jako dodatkową metrykę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ca6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = (\"accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd59aff1",
   "metadata": {},
   "source": [
    "I wytrenować go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35692f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = creditcard_model.fit(\n",
    "    x = creditcard_train_X,\n",
    "    y = creditcard_train_Y,\n",
    "    validation_split = 0.2, # 20% zbioru uczącego przeznaczonego na walidację\n",
    "    epochs = 5, # Liczba \"pętli/przejść\" bo całym zbiorze treningowym\n",
    "    batch_size = 256, # Wielkość próbki (batcha) dla jednej iteracji algorytmu SGD\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07124f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2937d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model.evaluate(creditcard_test_X, creditcard_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_predictions = creditcard_model.predict(creditcard_test_X)\n",
    "creditcard_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44cf578",
   "metadata": {},
   "source": [
    "Model może wydawać się dobry, jednakże wcale taki nie jest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a763f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(creditcard_test_Y[:, 1], np.argmax(creditcard_model.predict(creditcard_test_X), axis=-1),\n",
    "           rownames = [\"true\"], colnames = [\"predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0794463d",
   "metadata": {},
   "source": [
    "# Dropout i checkpointy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077b3d6",
   "metadata": {},
   "source": [
    "Jednym z powodów przez które nasz model zawiódł może być brak regularyzacji, która jest niezwykle ważna w przypadku mocno niezbalansowanych zbiorów lub kiepska architektura sieci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f1feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model2 = tf.keras.Sequential()\n",
    "creditcard_model2.add(\n",
    "    tf.keras.layers.Dense(units = 256, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"relu\", # Funkcja aktywacji\n",
    "                             input_shape = (29,)) # Liczba predyktorów - tylko w pierwszej warstwie\n",
    ")\n",
    "creditcard_model2.add(tf.keras.layers.Dropout(0.1))\n",
    "creditcard_model2.add(\n",
    "    tf.keras.layers.Dense(units = 256, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"relu\") # Funkcja aktywacji\n",
    ")\n",
    "creditcard_model2.add(tf.keras.layers.Dropout(0.1))\n",
    "creditcard_model2.add(\n",
    "    tf.keras.layers.Dense(units = 2, # Liczba neuronów w warstwie wyjścia\n",
    "                             activation = \"softmax\") # Funkcja aktywacji\n",
    ")\n",
    "creditcard_model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae6f89",
   "metadata": {},
   "source": [
    "Trenowanie sieci neuronowej może zająć dużo czasu, a rozwiązanie rzeczywistego problemu może zająć dni, tygodnie, a nawet miesiące. W tym czasie wiele rzeczy może pójść nie tak, na przykład jeśli twój komputer zresetuje się z nieznanego powodu, stracisz cały postęp i dużo czasu! Aby rozwiązać ten problem, możemy dodać punkt kontrolny modelu, który będzie zapisywać model w każdej epoce. Punkt kontrolny modelu jest jednym z wielu wywołań zwrotnych, których możesz używać w Keras podczas procesu szkolenia.\n",
    "\n",
    "Kolejnym przydatnym callbackiem jest **Early stopping** umożliwiający zatrzymanie procesu uczenia jeśli wyniki sieci nie ulegają polepszeniu. Jest to kolejna metoda regularyzacji zapobiegająca przeuczeniu modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model2.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = (\"accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e161529",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = creditcard_model2.fit(\n",
    "    x = creditcard_train_X,\n",
    "    y = creditcard_train_Y,\n",
    "    validation_split = 0.2, # 20% zbioru uczącego przeznaczonego na walidację\n",
    "    epochs = 100, # Liczba \"pętli/przejść\" bo całym zbiorze treningowym\n",
    "    batch_size = 256, # Wielkość próbki (batcha) dla jednej iteracji algorytmu SGD\n",
    "    verbose = 1,\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10),\n",
    "                tf.keras.callbacks.ModelCheckpoint(filepath = \"models/creditcard_best.hdf5\",\n",
    "                                                  monitor = \"val_loss\", save_best_only = True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model2.evaluate(creditcard_test_X, creditcard_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(creditcard_test_Y[:, 1], np.argmax(creditcard_model2.predict(creditcard_test_X), axis=-1),\n",
    "           rownames = [\"true\"], colnames = [\"predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9373f19",
   "metadata": {},
   "source": [
    "# MLP dla zadania regresji wieloklasowej - praca domowa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689844e0",
   "metadata": {},
   "source": [
    "W podobny sposób możemy zbudować model sekwencyjny dla problemu klasyfikacji wieloklasowej. Korzystając ze zbioru FASHION MNIST zbuduj sieć MLP, która klasyfikuje dany obraz do jedne z 10 klas:\n",
    "\n",
    " - 0\tT-shirt/top\n",
    " - 1\tTrouser\n",
    " - 2\tPullover\n",
    " - 3\tDress\n",
    " - 4\tCoat\n",
    " - 5\tSandal\n",
    " - 6\tShirt\n",
    " - 7\tSneaker\n",
    " - 8\tBag\n",
    " - 9\tAnkle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_train_X = pd.read_csv(\"data/fashion_mnist_train_X\", sep=\" \").to_numpy()\n",
    "fashion_mnist_test_X = pd.read_csv(\"data/fashion_mnist_test_X\", sep=\" \").to_numpy()\n",
    "fashion_mnist_train_Y = pd.read_csv(\"data/fashion_mnist_train_Y\", sep=\" \").to_numpy()\n",
    "fashion_mnist_test_Y = pd.read_csv(\"data/fashion_mnist_test_Y\", sep=\" \").to_numpy()\n",
    "\n",
    "fashion_mnist_train_X = fashion_mnist_train_X / 255\n",
    "fashion_mnist_test_X = fashion_mnist_test_X / 255\n",
    "\n",
    "print(fashion_mnist_train_X.shape)\n",
    "print(fashion_mnist_train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98daf291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(fashion_mnist_train_X[0,:].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a86aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Create MLP for fashion MNIST classification.\n",
    "# Change labels vectors to one-hot-encoding matrix using to_categorical() method\n",
    "\n",
    "# Model architecture:\n",
    "# Dense layer with 512 units and \"relu\" activation\n",
    "# Dropout layer with 20% drop rate\n",
    "# Dense layer with 512 units and \"relu\" activation\n",
    "# Dropout layer with 20% drop rate\n",
    "# Output dense layer (how many units and what activation should You use?)\n",
    "\n",
    "# Set SGD as optimizer and use categorical crossentropy as loss function. Use accuracy as additional metric.\n",
    "\n",
    "# Fit the model. Use 20% of the data for validation, 20 epochs and 128 samples for batch size.\n",
    "# Use model checkpoint and early stopping.\n",
    "\n",
    "# Evaluate model on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac5ef9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
