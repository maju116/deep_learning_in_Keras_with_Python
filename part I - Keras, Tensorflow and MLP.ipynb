{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c87b514",
   "metadata": {},
   "source": [
    "Zacznijmy od wczytania niezbędnych pakietów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b602c",
   "metadata": {},
   "source": [
    "# MLP dla zadania regresji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83d37f",
   "metadata": {},
   "source": [
    "W Keras możemy tworzyć modele na dwa różne sposoby:\n",
    "- zbudować model sekwencyjny - nakładamy nowe warstwy na poprzednie. Nie możemy używać wielu inputów i outputów w modelu.\n",
    "- używając API funkcyjnego - pozwala na uzycie wieli inputów i uotputów.\n",
    "\n",
    "Zaczniemy od modelu sekwencyjnego. Musimy zacząć od inicjalizacji modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f83119",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_train_X = pd.read_csv(\"data/boston_train_X\", sep=\" \").to_numpy()\n",
    "boston_test_X = pd.read_csv(\"data/boston_test_X\", sep=\" \").to_numpy()\n",
    "boston_train_Y = pd.read_csv(\"data/boston_train_Y\", sep=\" \").to_numpy()\n",
    "boston_test_Y = pd.read_csv(\"data/boston_test_Y\", sep=\" \").to_numpy()\n",
    "\n",
    "print(boston_train_X.shape)\n",
    "print(boston_train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e239ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbacf764",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f9dabc",
   "metadata": {},
   "source": [
    "W następnym kroku możemy dodać kilka warstw (pamiętaj, że nie musimy ponownie przypisywać modelu za pomocą `=`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33421632",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boston_model.add(\n",
    "    tf.keras.layers.Dense(units = 16, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"tanh\", # Funkcja aktywacji\n",
    "                             input_shape = (13,)) # Liczba predyktorów - tylko w pierwszej warstwie\n",
    ")\n",
    "boston_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b8ac6",
   "metadata": {},
   "source": [
    "Dlaczego mamy 224 parametry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3256a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "13 * 16 + 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8e67c",
   "metadata": {},
   "source": [
    "Po dodaniu warstwy ukrytej możemy dodać warstwę wyjściową:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model.add(\n",
    "    tf.keras.layers.Dense(units = 1, # Liczba neuronów w warstwie wyjścia - chcemy dostać 1 liczbę\n",
    "                             activation = \"linear\") # Funkcja liniowa dla regresji\n",
    ")\n",
    "boston_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b27f65",
   "metadata": {},
   "source": [
    "Możemy teraz skonfigurować model do treningu. Użyjemy SGD jako optymalizatora, MSE jako funkcji straty i dodamy MAE jako dodatkową metrykę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"mse\",\n",
    "    metrics = (\"mae\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85acce42",
   "metadata": {},
   "source": [
    "Jesteśmy gotowi do trenowania naszej pierwszej sieci neuronowej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dacb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = boston_model.fit(\n",
    "    x = boston_train_X,\n",
    "    y = boston_train_Y,\n",
    "    validation_split = 0.2, # 20% zbioru uczącego przeznaczonego na walidację\n",
    "    epochs = 5, # Liczba \"pętli/przejść\" bo całym zbiorze treningowym\n",
    "    batch_size = 30, # Wielkość próbki (batcha) dla jednej iteracji algorytmu SGD\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47177f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('model MAE')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f57ba",
   "metadata": {},
   "source": [
    "Możemy teraz ocenić wytrenowany model w testowym zestawie danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_model.evaluate(boston_test_X, boston_test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e862b2",
   "metadata": {},
   "source": [
    "I policzyć predykcje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_predictions = boston_model.predict(boston_test_X)\n",
    "boston_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc33904",
   "metadata": {},
   "source": [
    "Na koniec możemy zapisać nasz model na dysku twardym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101913a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "boston_model.save(\"models/boston_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f1ea8",
   "metadata": {},
   "source": [
    "# MLP dla zadania klasyfikacji binarnej"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185bb493",
   "metadata": {},
   "source": [
    "Budując MLP (lub inną sieć neuronową) dla zadania klasyfikacji musimy zmienić tylko kilka drobnych detali w naszym kodzie. Zacznijmy od wczytania zbioru danych z informacjami o fraudach na kartach kredytowych i inicjalizacji modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cc65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_train_X = pd.read_csv(\"data/creditcard_train_X\", sep=\" \").to_numpy()\n",
    "creditcard_test_X = pd.read_csv(\"data/creditcard_test_X\", sep=\" \").to_numpy()\n",
    "creditcard_train_Y = pd.read_csv(\"data/creditcard_train_Y\", sep=\" \").to_numpy()\n",
    "creditcard_test_Y = pd.read_csv(\"data/creditcard_test_Y\", sep=\" \").to_numpy()\n",
    "\n",
    "print(creditcard_train_X.shape)\n",
    "print(creditcard_train_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240de081",
   "metadata": {},
   "source": [
    "Zanim zbudujemy model, przekształcimy wektor odpowiedzi (klas) do formatu one-hot-encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be130f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_train_Y = tf.keras.utils.to_categorical(creditcard_train_Y, 2)\n",
    "creditcard_test_Y = tf.keras.utils.to_categorical(creditcard_test_Y, 2)\n",
    "print(creditcard_train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddedee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3604d48c",
   "metadata": {},
   "source": [
    "Następnie dodajmy warstwy ukryte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85238d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model.add(\n",
    "    tf.keras.layers.Dense(units = 20, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"relu\", # Funkcja aktywacji\n",
    "                             input_shape = (29,)) # Liczba predyktorów - tylko w pierwszej warstwie\n",
    ")\n",
    "creditcard_model.add(\n",
    "    tf.keras.layers.Dense(units = 10, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"relu\") # Funkcja aktywacji\n",
    ")\n",
    "creditcard_model.add(\n",
    "    tf.keras.layers.Dense(units = 5, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"relu\") # Funkcja aktywacji\n",
    ")\n",
    "creditcard_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c06c97b",
   "metadata": {},
   "source": [
    "Oraz warstwę wyjściową:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f665bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model.add(\n",
    "    tf.keras.layers.Dense(units = 2, # Liczba neuronów w warstwie wyjścia - dwie klasy\n",
    "                             activation = \"softmax\") # Funkcja aktywacji - softmax dla klasykikacji\n",
    ")\n",
    "creditcard_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58794f1",
   "metadata": {},
   "source": [
    "Możemy teraz skonfigurować model do treningu. Użyjemy SGD jako optymalizatora, Entropii Krzyżowej jako funkcji straty i dodamy Accuracy jako dodatkową metrykę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ca6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = (\"accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd59aff1",
   "metadata": {},
   "source": [
    "I wytrenować go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35692f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = creditcard_model.fit(\n",
    "    x = creditcard_train_X,\n",
    "    y = creditcard_train_Y,\n",
    "    validation_split = 0.2, # 20% zbioru uczącego przeznaczonego na walidację\n",
    "    epochs = 5, # Liczba \"pętli/przejść\" bo całym zbiorze treningowym\n",
    "    batch_size = 256, # Wielkość próbki (batcha) dla jednej iteracji algorytmu SGD\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07124f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2937d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model.evaluate(creditcard_test_X, creditcard_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_predictions = creditcard_model.predict(creditcard_test_X)\n",
    "creditcard_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44cf578",
   "metadata": {},
   "source": [
    "Model może wydawać się dobry, jednakże wcale taki nie jest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a763f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(creditcard_test_Y[:, 1], np.argmax(creditcard_model.predict(creditcard_test_X), axis=-1),\n",
    "           rownames = [\"true\"], colnames = [\"predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0794463d",
   "metadata": {},
   "source": [
    "# Dropout i checkpointy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077b3d6",
   "metadata": {},
   "source": [
    "Jednym z powodów przez które nasz model zawiódł może być brak regularyzacji, która jest niezwykle ważna w przypadku mocno niezbalansowanych zbiorów lub kiepska architektura sieci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f1feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model2 = tf.keras.Sequential()\n",
    "creditcard_model2.add(\n",
    "    tf.keras.layers.Dense(units = 256, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"relu\", # Funkcja aktywacji\n",
    "                             input_shape = (29,)) # Liczba predyktorów - tylko w pierwszej warstwie\n",
    ")\n",
    "creditcard_model2.add(tf.keras.layers.Dropout(0.1))\n",
    "creditcard_model2.add(\n",
    "    tf.keras.layers.Dense(units = 256, # Liczba neuronów w warstwie ukrytej\n",
    "                             activation = \"relu\") # Funkcja aktywacji\n",
    ")\n",
    "creditcard_model2.add(tf.keras.layers.Dropout(0.1))\n",
    "creditcard_model2.add(\n",
    "    tf.keras.layers.Dense(units = 2, # Liczba neuronów w warstwie wyjścia\n",
    "                             activation = \"softmax\") # Funkcja aktywacji\n",
    ")\n",
    "creditcard_model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae6f89",
   "metadata": {},
   "source": [
    "Trenowanie sieci neuronowej może zająć dużo czasu, a rozwiązanie rzeczywistego problemu może zająć dni, tygodnie, a nawet miesiące. W tym czasie wiele rzeczy może pójść nie tak, na przykład jeśli twój komputer zresetuje się z nieznanego powodu, stracisz cały postęp i dużo czasu! Aby rozwiązać ten problem, możemy dodać punkt kontrolny modelu, który będzie zapisywać model w każdej epoce. Punkt kontrolny modelu jest jednym z wielu wywołań zwrotnych, których możesz używać w Keras podczas procesu szkolenia.\n",
    "\n",
    "Kolejnym przydatnym callbackiem jest **Early stopping** umożliwiający zatrzymanie procesu uczenia jeśli wyniki sieci nie ulegają polepszeniu. Jest to kolejna metoda regularyzacji zapobiegająca przeuczeniu modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model2.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = (\"accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e161529",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = creditcard_model2.fit(\n",
    "    x = creditcard_train_X,\n",
    "    y = creditcard_train_Y,\n",
    "    validation_split = 0.2, # 20% zbioru uczącego przeznaczonego na walidację\n",
    "    epochs = 100, # Liczba \"pętli/przejść\" bo całym zbiorze treningowym\n",
    "    batch_size = 256, # Wielkość próbki (batcha) dla jednej iteracji algorytmu SGD\n",
    "    verbose = 1,\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10),\n",
    "                tf.keras.callbacks.ModelCheckpoint(filepath = \"models/creditcard_best.hdf5\",\n",
    "                                                  monitor = \"val_loss\", save_best_only = True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_model2.evaluate(creditcard_test_X, creditcard_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(creditcard_test_Y[:, 1], np.argmax(creditcard_model2.predict(creditcard_test_X), axis=-1),\n",
    "           rownames = [\"true\"], colnames = [\"predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9373f19",
   "metadata": {},
   "source": [
    "# MLP dla zadania regresji wieloklasowej - praca domowa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689844e0",
   "metadata": {},
   "source": [
    "W podobny sposób możemy zbudować model sekwencyjny dla problemu klasyfikacji wieloklasowej. Korzystając ze zbioru FASHION MNIST zbuduj sieć MLP, która klasyfikuje dany obraz do jedne z 10 klas:\n",
    "\n",
    " - 0\tT-shirt/top\n",
    " - 1\tTrouser\n",
    " - 2\tPullover\n",
    " - 3\tDress\n",
    " - 4\tCoat\n",
    " - 5\tSandal\n",
    " - 6\tShirt\n",
    " - 7\tSneaker\n",
    " - 8\tBag\n",
    " - 9\tAnkle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_train_X = pd.read_csv(\"data/fashion_mnist_train_X\", sep=\" \").to_numpy()\n",
    "fashion_mnist_test_X = pd.read_csv(\"data/fashion_mnist_test_X\", sep=\" \").to_numpy()\n",
    "fashion_mnist_train_Y = pd.read_csv(\"data/fashion_mnist_train_Y\", sep=\" \").to_numpy()\n",
    "fashion_mnist_test_Y = pd.read_csv(\"data/fashion_mnist_test_Y\", sep=\" \").to_numpy()\n",
    "\n",
    "fashion_mnist_train_X = fashion_mnist_train_X / 255\n",
    "fashion_mnist_test_X = fashion_mnist_test_X / 255\n",
    "\n",
    "print(fashion_mnist_train_X.shape)\n",
    "print(fashion_mnist_train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98daf291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(fashion_mnist_train_X[0,:].reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a86aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Create MLP for fashion MNIST classification.\n",
    "# Change labels vectors to one-hot-encoding matrix using to_categorical() method\n",
    "\n",
    "# Model architecture:\n",
    "# Dense layer with 512 units and \"relu\" activation\n",
    "# Dropout layer with 20% drop rate\n",
    "# Dense layer with 512 units and \"relu\" activation\n",
    "# Dropout layer with 20% drop rate\n",
    "# Output dense layer (how many units and what activation should You use?)\n",
    "\n",
    "# Set SGD as optimizer and use categorical crossentropy as loss function. Use accuracy as additional metric.\n",
    "\n",
    "# Fit the model. Use 20% of the data for validation, 20 epochs and 128 samples for batch size.\n",
    "# Use model checkpoint and early stopping.\n",
    "\n",
    "# Evaluate model on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac5ef9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
